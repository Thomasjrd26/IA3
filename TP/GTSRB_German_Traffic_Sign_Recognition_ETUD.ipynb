{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn3e5SegBx0f"
   },
   "source": [
    "# TP2 : Classification de panneaux de circulation - GTSRB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ig6tmbBRuo2"
   },
   "source": [
    "Le **jeu de données GTSRB** (German Traffic Sign Recognition Benchmark) est un jeu de données comportant **plus de 50,000 images** représentant **43 classes de panneaux de signalisation**. \n",
    "\n",
    "Ce dataset peut être téléchargé depuis ce [site](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign).\n",
    "\n",
    "**NE PAS TELECHARGER LE DATASET**\n",
    "\n",
    "<u>ATTENTION</u> : Le dataset est gros (626Mo)... Dans ce TP nous n'allons utilisé qu'une partie du dataset pour éviter des longs téléchargements : 30% des données d'entrainement, 10% des données de validation et 10% des données de test. Les données ont déjà été mélangées (shuffle), il n'est donc pas nécessaire de le faire.\n",
    "\n",
    "---\n",
    "\n",
    "### Dans ce TP vous allez :\n",
    "- **Visualiser** les données d'entrainement\n",
    "- Afficher **l'histogramme du nombre d'observation par classe** (ou population) pour le jeu d'entrainement et de test\n",
    "- **Redimensionner toutes les images** dans un même format (30x30 pixels)\n",
    "- Construire et comparer **différents réseaux de neurone** pour faire de la classification multi-classes pour ces 43 panneaux de signalisation.\n",
    "- Utiliser des techniques de **data augmentation** afin d'améliorer les performances du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb0U_8wvRuo2",
    "tags": []
   },
   "source": [
    "## Step 1 - Import and Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAnGHjNcRuo3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model, clone_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CK_GfLYwRuo7",
    "tags": []
   },
   "source": [
    "## Step 2 - Read and prepare the GTSRB dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapes à suivre pour décompresser le dataset GTSRB sur le disque local de la VM Colab:\n",
    "1. Ouvrir l'explorateur de fichiers et aller dans DocumentsCours/BUT/BUT2/IA/tp2\n",
    "2. Récupérer le fichier GTSRB.zip et le copier sur votre Google drive\n",
    "3. Exécuter les cellules suivantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage du drive sur la VM\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "%cd /content/gdrive/MyDrive\n",
    "\n",
    "# On decompresse le dataset depuis le drive vers le disque local /content/sample_data de la VM\n",
    "!unzip -qq GTSRB.zip -d /content/sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us define the path where the dataset is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "dataset_path = \"sample_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYRhl9oFRuo4"
   },
   "source": [
    "#### Upload GTSRB compressed dataset (.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-zzYXC_a3cZ",
    "outputId": "2a97835b-d2d4-417b-b054-79bec4252be3"
   },
   "outputs": [],
   "source": [
    "#! [ ! -f GTSRB.zip ] && echo \".zip dosn't exist\" && wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zV_jKW96OizJAPV_ZLbSFbAkaK4rD6CZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zV_jKW96OizJAPV_ZLbSFbAkaK4rD6CZ\" -O GTSRB.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cteME3GRuo5"
   },
   "source": [
    "#### Unzip the dataset to the Colab machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QE4UwORBRuo5",
    "outputId": "aba01a16-fef5-4c33-d7b6-089671f2edc3"
   },
   "outputs": [],
   "source": [
    "# if sample_data/RGB dosn't exist then exctract the dataset into sample_data/\n",
    "#! [ ! -d /content/sample_data/train ] && echo \"train doesn't exist\" && unzip -qq GTSRB.zip -d /content/sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bulQxzTPt9Lz"
   },
   "source": [
    "#### Data are organized as follows :  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "3MusFeQwRuo7"
   },
   "source": [
    "gtsrb-german-trafic-sign\n",
    "     |\n",
    "     ---- Train  \n",
    "     |      |  \n",
    "     |      --- 0\n",
    "     |      --- 1\n",
    "     |      ...\n",
    "     |      --- 42\n",
    "     ---- Test  \n",
    "     |      |  \n",
    "     |      --- 0\n",
    "     |      --- 1\n",
    "     |      ...\n",
    "     |      --- 42\n",
    "     ---- Meta  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0IcqB96t9L0"
   },
   "source": [
    "#### A function to download the train, validation and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZ4SpCT6Ruo8"
   },
   "outputs": [],
   "source": [
    "def load_dataset_from_folder(folder_path = 'train'):\n",
    "    # data va contenir toutes les données d'entrainement\n",
    "    x_train = []\n",
    "    paths_list = []\n",
    "    y_train = []\n",
    "    classes = 43\n",
    "    \n",
    "    # Retrieving the images and their labels \n",
    "    for i in range(classes):\n",
    "        # On parcours tous les sous-répertoires dans train\n",
    "        # Il y a un répertoire par classe  \n",
    "        path = os.path.join(folder_path, str(i))\n",
    "        # Images est une liste qui contient de tous les fichiers du sous répertoire\n",
    "        images = os.listdir(path)\n",
    "\n",
    "        # On parcours toutes les images du sous-répertoire\n",
    "        for a in images:\n",
    "            try:\n",
    "                # On ouvre l'image \n",
    "                image = Image.open(path + '/'+ a)\n",
    "                # On redimensionne toutes les images en 30x30 pixels\n",
    "                image = image.resize((30,30))\n",
    "                # On enregistre chaque image redimensionnée dans un tableau numpy\n",
    "                image = np.array(image)\n",
    "        \n",
    "                # Data contient toutes les images et leur label\n",
    "                x_train.append(image) \n",
    "                # Data contient toutes les images et leur label\n",
    "                y_train.append(i) \n",
    "            except:\n",
    "                print(\"Error loading image\")\n",
    "    \n",
    "    return np.asarray(x_train), np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb720nZjt9L1"
   },
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EzjqeUQRuo9"
   },
   "outputs": [],
   "source": [
    "x_train, y_train  = load_dataset_from_folder(folder_path = dataset_path + '/train')\n",
    "x_val, y_val      = load_dataset_from_folder(folder_path = dataset_path + '/val')\n",
    "x_test, y_test    = load_dataset_from_folder(folder_path = dataset_path + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhedDYotRuo-",
    "outputId": "493bb141-2274-44da-bb19-70ea9353db76"
   },
   "outputs": [],
   "source": [
    "# Affichage de la forme des données d'entrainement\n",
    "print(\"Shape of train images is:\", x_train.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae6OiGHht9L3"
   },
   "source": [
    "### <font color=\"red\">**Exo1**</font> : Afficher le nombre d'observations utilisées pour l'entrainement (train), la validation (val) et le test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsdgzRTnRuo9",
    "outputId": "d11438b3-b4a8-4acb-8b0b-8f1097a16c20"
   },
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rLlwcKNCz2E"
   },
   "source": [
    "### Afficher quelques images du dataset (1 image par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dgtk9JfnyChg"
   },
   "outputs": [],
   "source": [
    "# On crée un dictionnaire où la clef est le n° de la classe et la valeur le nom de la classe (description du panneau)\n",
    "label_map = {\n",
    "    0: '20_speed',\n",
    "    1: '30_speed',\n",
    "    2: '50_speed',\n",
    "    3: '60_speed',\n",
    "    4: '70_speed',\n",
    "    5: '80_speed',\n",
    "    6: '80_lifted',\n",
    "    7: '100_speed',\n",
    "    8: '120_speed',\n",
    "    9: 'no_overtaking_general',\n",
    "    10: 'no_overtaking_trucks',\n",
    "    11: 'right_of_way_crossing',\n",
    "    12: 'right_of_way_general',\n",
    "    13: 'give_way',\n",
    "    14: 'stop',\n",
    "    15: 'no_way_general',\n",
    "    16: 'no_way_trucks',\n",
    "    17: 'no_way_one_way',\n",
    "    18: 'attention_general',\n",
    "    19: 'attention_left_turn',\n",
    "    20: 'attention_right_turn',\n",
    "    21: 'attention_curvy',\n",
    "    22: 'attention_bumpers',\n",
    "    23: 'attention_slippery',\n",
    "    24: 'attention_bottleneck',\n",
    "    25: 'attention_construction',\n",
    "    26: 'attention_traffic_light',\n",
    "    27: 'attention_pedestrian',\n",
    "    28: 'attention_children',\n",
    "    29: 'attention_bikes',\n",
    "    30: 'attention_snowflake',\n",
    "    31: 'attention_deer',\n",
    "    32: 'lifted_general',\n",
    "    33: 'turn_right',\n",
    "    34: 'turn_left',\n",
    "    35: 'turn_straight',\n",
    "    36: 'turn_straight_right',\n",
    "    37: 'turn_straight_left',\n",
    "    38: 'turn_right_down',\n",
    "    39: 'turn_left_down',\n",
    "    40: 'turn_circle',\n",
    "    41: 'lifted_no_overtaking_general',\n",
    "    42: 'lifted_no_overtaking_trucks'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd-0nP0et9L4"
   },
   "source": [
    "### <font color=\"red\">**Exo2**</font> : Afficher 1 image du jeu d'entrainement pour chacune des 43 classes (celle que vous voulez) \n",
    "<u>Indications</u>:  \n",
    "+ Faire une boucle de 0 à 42\n",
    "+ Parcourir un à un les sous-réperoires (construire le chemin pour y accéder en utilisant le module os)\n",
    "+ Récupérer les images du sous-répertoire\n",
    "+ Ouvrir une des images et l'afficher\n",
    "+ Mettre le nom du label en titre de l'image (utiliser pour cela le dictionnaire label_map défini plus haut)\n",
    "+ Afficher plusieurs images par ligne (7 par exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x2mLqdCN1fgY",
    "outputId": "c0e8c06d-4095-48da-e30c-4a3fee189169"
   },
   "outputs": [],
   "source": [
    "classes = 43\n",
    "plt.figure(figsize=(17, 30))   \n",
    "\n",
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSI_csgFt9L5"
   },
   "source": [
    "### Comprendre le dataset GTSRB...\n",
    "+ Ce dataset est fourni avec 3 fichiers CSV qui décrivent les données d'entrainement et de test\n",
    "+ La 1ère ligne de ces fichiers contient les champs suivants : `Filename ; Width ; Height ; Roi.X1 ; Roi.Y1 ; Roi.X2 ; Roi.Y2 ; ClassId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "hj_8vUz5t9L5",
    "outputId": "12439b1c-e93b-452e-8bf9-7867ab315846"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dataset_path}/Test.csv', header=0)   # lecture du contenu du fichier CSV sous forme d'un dataframe pandas \n",
    "display(df.head(20))   # On visualise les 20 premières lignes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meT6ogRZt9L6"
   },
   "source": [
    "### <font color=\"red\">**Exo3**</font> : \n",
    "+ Regarder attentivement la taille des images...\n",
    "+ Est-ce que cela peut poser un problème pour un modèle de machine learning ?\n",
    "+ Que faudrait-il faire à votre avis ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YGKY1C_t9L7"
   },
   "outputs": [],
   "source": [
    "# Votre réponse :\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlEhU_7aRuo-"
   },
   "source": [
    "### <font color=\"red\">**Exo4**</font> :  Déterminer le nombre d'observations/echantillons par classe\n",
    "---\n",
    "+ Afficher l'histogramme du nombre d'échantillons d'entrainement et de test par classe (utiliser y_train et y_test)\n",
    "+ Pour l'histogramme, essayer d'afficher le nom de chaque classe (par exemple '20_speed') avec un alignement vertical \n",
    "+ Afficher aussi le pourcentage d'échantillon pour chaque classe\n",
    "+ Est-ce que ce jeu de données est équilibré (en termes de nombre d'échantillons par classe)?\n",
    "\n",
    "<u>Indice</u> : utiliser le module matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "fO4pBMqcEZWR",
    "outputId": "f92449f3-abf7-461a-d5aa-71a235393f7b"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSL6FyD-t9L7"
   },
   "source": [
    "#### Affichage du pourcentage d'échantillon pour chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvuhbHoNRuo-",
    "outputId": "6fd8464c-5208-468e-bb91-d87d09f55428",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j295KSX0Ruo-"
   },
   "source": [
    "### Normalisation des données d'entrainement\n",
    "Attention : changement de nom pour les données d'entrainement, de validation et de test (X en majuscule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mH4BRIKvRuo-"
   },
   "outputs": [],
   "source": [
    "X_train = x_train/255.0\n",
    "X_val   = x_val/255.0\n",
    "X_test  = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUIdgFVHt9L8",
    "outputId": "c3e0c9ae-009d-4ff2-c84e-66771b0455f8"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrWzLn-TRuo-"
   },
   "source": [
    "## Step 3 - Build a CNN model with Keras\n",
    "\n",
    "### <font color=\"red\">**Exo5**</font> : Construire un modèle CNN comportant les couches suivantes :   \n",
    "+ 1 couche de **Convolution 2D** avec 32 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **Convolution 2D** avec 64 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **Convolution 2D** avec 128 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "---\n",
    "+ 1 couche **Flatten**\n",
    "+ 1 couche **Dense** de 128 neurones avec activation relu\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.5\n",
    "+ 1 couche **Dense** de sortie de 43 neurones avec activation softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clGSWcRnRuo-"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(30, 30, 3), padding='same'))\n",
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Po62BN_1Ruo_",
    "outputId": "86a68c4f-40be-4349-dc72-d587e42fe3a5"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxGBjuF0t9MA"
   },
   "source": [
    "### <font color=\"red\">**Exo6**</font> : Retrouver par le calcul le nombre de paramètres entrainables de ce modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8vIGirBt9MA"
   },
   "outputs": [],
   "source": [
    "# Votre réponse :\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xSkbIcdt9MA"
   },
   "source": [
    "## Step 4 - Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piGOG-u1RupA"
   },
   "source": [
    "#### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewL39j8YRupA"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCb26q4xRupA"
   },
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVp-n62Et9MC"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs      = 15\n",
    "batch_size  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekqjDsrhRupA",
    "outputId": "d0705083-64ca-4d3c-d05b-3464de34607f"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                     batch_size=512, \n",
    "                     epochs=epochs, \n",
    "                     validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVX2BevWRupA"
   },
   "source": [
    "#### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g15X-XY0RupB"
   },
   "outputs": [],
   "source": [
    "model.save('model1.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHzfb6QERupB"
   },
   "source": [
    "### <font color=\"red\">**Exo7**</font> : Display history of the loss and Accuracy according to the number of epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1M6LB6dRupC"
   },
   "source": [
    "Display loss and accuracy VS. epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "50TRSN91galq",
    "outputId": "5949e49f-6d8f-4433-a153-f27d60a8f2ce"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrooEqBURupC"
   },
   "source": [
    "## Step 5 - Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4LaXVIuRupD",
    "outputId": "c2bb835b-b0d1-4dd1-e3d4-21d1f624481f"
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "# Accuracy with the test data\n",
    "print(f\"Model accuracy on test data: {accuracy_score(y_test, pred)*100:2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbWWUEd8RupD"
   },
   "source": [
    "### <font color=\"red\">**Exo8**</font> : Afficher precision, recall et f1-score du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADclh8u2RupD",
    "outputId": "e8b886fc-032e-43d0-bc48-dfdc1c317bc9"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4P9y5wyRupD"
   },
   "source": [
    "### <font color=\"red\">**Exo9**</font> : Afficher la matrice de confusion\n",
    "Indication : la matrice de confusion est grande (43 par 43). Vous pouvez vous limitez à 10 ou 20 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "RFF5fs5fRupE",
    "outputId": "4a7a2753-58da-4ac7-febd-2e577f93d456"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnIl9Wgtt9MG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5uJD3YZt9MG"
   },
   "source": [
    "## Let's build another CNN model with Keras\n",
    "\n",
    "Nous allons construire un autre modèle CNN afin de tenter d'améliorer les performances... \n",
    "### <font color=\"red\">**Exo10**</font> : Construire un modèle CNN comportant les couches suivantes :   \n",
    "\n",
    "+ 1 couche de **Convolution 2D** avec 16 filtres de taille 3x3 et activation 'relu'\n",
    "+ 1 couche de **Convolution 2D** avec 32 filtres de taille 3x3 et activation 'relu'\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **Convolution 2D** avec 64 filtres de taille 3x3 et activation 'relu'\n",
    "+ 1 couche de **Convolution 2D** avec 128 filtres de taille 3x3 et activation 'relu'\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **BatchNormalization**\n",
    "---\n",
    "+ 1 couche **Flatten**\n",
    "+ 1 couche **Dense** de 512 neurones avec activation relu\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.5\n",
    "+ 1 couche **Dense** de sortie de 43 neurones avec activation softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f34aPwYSg8V9"
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = keras.models.Sequential([    \n",
    "# TO BE COMPLETED\n",
    "# ....\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(30,30,3)),  # 1ère couche\n",
    "    # ...\n",
    "    # ...\n",
    "    keras.layers.Dense(43, activation='softmax')      # Dernière couche\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7JCVYZflW_3",
    "outputId": "68bcb3e5-6b31-4567-fc11-a5ed9ac5b413"
   },
   "outputs": [],
   "source": [
    "# !!!!! Noter l'augmentation du nombre de paramètres entrainables par rapport au model1...\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP7YiDECt9MH"
   },
   "source": [
    "### On clone le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYJzY6ntt9MH"
   },
   "outputs": [],
   "source": [
    "model2 = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xy-Zekikt9MI"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "lr = 0.001\n",
    "epochs = 15  # ou 30\n",
    "batch_size=32\n",
    "opt = Adam(learning_rate=lr, beta_1 = lr/(epochs * 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lEn3yh8t9MI"
   },
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDwp-E5Qi7me"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGc4DLT5t9MI"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vx1kawOzj-Zv",
    "outputId": "6eee21c9-a713-4cf1-84e6-7e0e924ca81f"
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train, y_train, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, \n",
    "                      validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOSZZc2nt9MJ"
   },
   "source": [
    "### Sauvegarde du modèle entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_U8nmict9MJ"
   },
   "outputs": [],
   "source": [
    "model2.save('model2.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1jl-De6t9MK"
   },
   "source": [
    "### Display history of the loss and Accuracy according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "m8zq3Vbdl3fu",
    "outputId": "3181f0e3-56af-4a2f-d9cc-5525252253b0"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5NfW8GLt9MK"
   },
   "source": [
    "### Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mbQ8xepmAOU",
    "outputId": "fe09ba0a-57c6-46f5-c704-69c2f6ec2365"
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(model2.predict(X_test), axis=-1)\n",
    "# Accuracy with the test data\n",
    "print(f\"Model accuracy on test data: {accuracy_score(y_test, pred)*100:2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpCV6Z_eRupE"
   },
   "source": [
    "# Utilisation de techniques de data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBi0-rV_RupE"
   },
   "source": [
    "### On clone un nouveau modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_R0e5Y8WRupF"
   },
   "outputs": [],
   "source": [
    "model3 = clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx0qW0ZnRupF"
   },
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3N-uhkrRupF"
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOyBvZVXRupF"
   },
   "source": [
    "### <font color=\"red\">**Exo11**</font> : Etudier les différentes techniques de data augmentation qui vont être utilisées lors de l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sdl9ZRolRupG"
   },
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sHW89S2RupG"
   },
   "source": [
    "### Entrainement du modèle avec de la data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y23d_tM-RupG",
    "outputId": "86254fe5-ea47-4709-ac4a-c01b215b15b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history3 = model3.fit(aug.flow(X_train, y_train, batch_size=32), epochs=15, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k76D1vwPt9MM"
   },
   "source": [
    "### Sauvegarde du modèle entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUAyyKWpRupH"
   },
   "outputs": [],
   "source": [
    "model3.save('model3.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02Z70iAzt9MN"
   },
   "source": [
    "### Display history of the loss and Accuracy according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "tTQt2Rk3t9MN",
    "outputId": "eef1ed96-eab2-49e7-b402-7ca761745ee0"
   },
   "outputs": [],
   "source": [
    "# TO BE COMPLETED\n",
    "# ....\n",
    "pd.DataFrame(history3.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n04kbHIMRupI"
   },
   "source": [
    "### Validate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgBiL6jVRupI",
    "outputId": "e1084489-4f74-46ed-88f7-4b4600c1d622"
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(model3.predict(X_test), axis=-1)\n",
    "print(f\"Model accuracy on test data: {accuracy_score(y_test, pred)*100:2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPUeCpRHRupI",
    "tags": []
   },
   "source": [
    "### Conclusion : est-ce que la data augmentation a permis une amélioration des performances pour ce dataset ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_MMm6wJRupJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a68GB-w4t9MR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d6a498548973d6f5469c2aab36e4824c85597fafa5ba201e254549f1e0fdecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
