{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Object Recognition Task using MLP and CNN on CIFAR-10 Dataset\n",
    "Dans ce TP nous allons faire de la classification multi-classes de 10 types d'objets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras import datasets, layers, models\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.python.platform.build_info as build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement et analyse du dataset CIFAR-10 (depuis les jeux de données Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du jeu de données CIFAR-10 et division en jeu d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo1**</font> :  \n",
    "- Combien d'images contient le jeu de données d'entrainement? et le jeu de test?  \n",
    "\n",
    "- Quelle est la dimension des images d'entrée et le nombre de canaux ?  \n",
    "\n",
    "- Quelle est la dimension du tenseur d'entrée ?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponses: \n",
    "print(_____.____)\n",
    "print(_____.____)\n",
    "print(_____.____)\n",
    "print(_____.____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo2**</font> :  \n",
    "- Combien y a-t-il de classes de sortie ?  \n",
    "\n",
    "- Quelles sont les valeurs des labels ?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponses: \n",
    "print(_____(train_labels))\n",
    "print(_____(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation d'une liste de tous les labels pour les classes\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de quelques images du jeu de données d'entrainement (train_images) \n",
    "On affiche le label de la classe correspondante (en utilisant class_names défini précédemment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for i in range (25):    # for first 25 images\n",
    "  plt.subplot(5, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "  plt.xlabel(class_names[train_labels[i][0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo3**</font> :  \n",
    "- Déterminer le nombre d'observations par classe dans le jeu d'entrainement et de test.  \n",
    "\n",
    "- Est-ce un jeu de données équilibré ?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse:\n",
    "train_labels_count = np.unique(______, return_counts=True)\n",
    "for i in range(len(train_labels_count[0])):\n",
    "    print(f\"Label {i} : {_____} ({_____/_____*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse:\n",
    "test_labels_count = np.unique(______, return_counts=True)\n",
    "for i in range(len(test_labels_count[0])):\n",
    "    print(f\"Label {i} : {_____} ({_____/_____*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- Comme nous allons utiliser un MLP, il est nécessaire de changer la forme (`reshape`) du tenseur d'entrée (de la forme **(50000, 32, 32, 3)**) en un tenseur de la forme **(50000, 3072)**\n",
    "- **Normalisation** des valeurs de pixel entre **[0-1]**\n",
    "- Les labels de sortie sont mis sous la forme `categorical` car nous allons utiliser une loss 'categorical_crossentropy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo4**</font> : Compléter le code de la cellule suivante afin\n",
    "- d'adapter la forme des données d'entrainement et de test au format attendu par le MLP\n",
    "- de normaliser les données d'entrée (normalisation min-max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape du tenseur d'entrée\n",
    "X_train = np.reshape(train_images,(_____,_____))\n",
    "X_test = np.reshape(test_images,(_____,_____))\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalisation\n",
    "X_train = X_train / _____\n",
    "X_test = X_test / _____\n",
    "\n",
    "# Comme nous allons utiliser une loss 'categorical_crossentropy', nous devons avoir les labels de sortie sous la forme 'categorical' \n",
    "num_classes = 10\n",
    "Y_train = to_categorical(_____, num_classes)\n",
    "Y_test = to_categorical(_____, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entrainement d'un Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color=\"red\">**Exo5**</font> : Construire un modèle MLP comportant les couches suivantes  \n",
    "+ 1 couche **Dense** de 256 neurones avec activation 'relu'\n",
    "+ 1 couche **Dense** de 256 neurones avec activation 'relu'\n",
    "+ 1 couche **Dense** de sortie de 10 neurones avec activation 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse :\n",
    "MLP_model = Sequential()\n",
    "MLP_model.add(_____)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "MLP_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the MLP\n",
    "- Batch Size : 64\n",
    "- Nb epochs : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = MLP_model.fit(X_train, Y_train, epochs=20, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo6**</font> : Sauvegarder le MLP entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model._____('MLP_CIFAR10_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP_model = tf.keras.models.load_model('MLP_CIFAR10_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo7**</font> : Afficher les courbes de loss et d'accuracy du MLP en fonction du nombre d'epoch. Que concluez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curve\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy curve\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo8**</font> : Evaluation du modèle MLP sur les données de test. Afficher l'accuracy obtenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = MLP_model._____(_____, _____, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le MLP a une accuracy de {score[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les métriques (precision, recall...) et la matrice de confusion du MLP (sur les données de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predict function returns a 2-dimension array (10000, 10). \n",
    "# For each test input, it returns a probability for the 10 output classes\n",
    "y_softmax = MLP_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argmax numpy function returns the class having the highest probability\n",
    "y_pred = np.argmax(y_softmax, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo9**</font> : A l'aide la fonction `classification_report` afficher la précision, recall et f1-score pour le MLP. Conclure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(_____, _____, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo10**</font> : Afficher et analyser la matrice de confusion obtenue à partir du MLP. Quelles classes posent plus particulièrement problème ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "labels_to_display=[]\n",
    "for i in range(NUM_CLASS):\n",
    "    labels_to_display.append(i)\n",
    "    \n",
    "label_names = []\n",
    "label_ticks = []\n",
    "for key in label_map:\n",
    "  label_names.append(label_map[key])\n",
    "  label_ticks.append(key)\n",
    "    \n",
    "# Construction de la matrice de confusion\n",
    "cm = confusion_matrix(_____, _____, normalize=None, labels=labels_to_display)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = ______)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cmap = plt.get_cmap('Blues')\n",
    "disp.plot(ax=ax, cmap=cmap, xticks_rotation=\"vertical\")\n",
    "plt.xticks(label_ticks[0:NUM_CLASS], label_names[0:NUM_CLASS], rotation='vertical')\n",
    "plt.yticks(label_ticks[0:NUM_CLASS], label_names[0:NUM_CLASS], rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Entrainement d'un Réseau de Neurones Convolutif (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour le CNN, il n'est pas nécessaire de changer la forme des données d'entrainement et de test \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One hot encoding the target class (labels)\n",
    "num_classes = 10\n",
    "Y_train = to_categorical(train_labels, num_classes)\n",
    "Y_test = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color=\"red\">**Exo11**</font> : Construire un modèle CNN comportant les couches suivantes  \n",
    "+ 1 couche de **Convolution 2D** avec 32 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **Convolution 2D** avec 32 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.3\n",
    "---\n",
    "+ 1 couche de **Convolution 2D** avec 64 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **Convolution 2D** avec 64 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.5\n",
    "---\n",
    "+ 1 couche de **Convolution 2D** avec 128 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **Convolution 2D** avec 128 filtres de taille 3x3, padding='same' et activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **MaxPooling 2D** de taille 2x2\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.5\n",
    "---\n",
    "+ 1 couche **Flatten**\n",
    "+ 1 couche **Dense** de 128 neurones avec activation 'relu'\n",
    "+ 1 couche de **BatchNormalization**\n",
    "+ 1 couche de **dropout** avec une probabilité de 0.5\n",
    "+ 1 couche **Dense** de sortie de 10 neurones avec activation 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sequential model and adding layers to it\n",
    "CNN_model = Sequential()\n",
    "\n",
    "CNN_model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "CNN_model.add(layers._____)\n",
    "CNN_model.add(layers._____)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the model summary\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "- Optimizer used during Back Propagation for weight and bias adjustment - Adam (adjusts the learning rate adaptively).\n",
    "- Loss Function used - Categorical Crossentropy (used when multiple categories/classes are present).\n",
    "- Metrics used for evaluation - Accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model\n",
    "- Batch Size : 64\n",
    "- Nb epochs : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = CNN_model.fit(X_train, Y_train, batch_size=64, epochs=20, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo12**</font> : Sauvegarder le CNN entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model._____('CNN_CIFAR10_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recréé exactement le même model, incluant poids et optimizer.\n",
    "# CNN_model = tf.keras.models.load_model('CNN_CIFAR10_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo13**</font> : Afficher les courbes de loss et d'accuracy du CNN en fonction du nombre d'epoch. Que concluez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curve\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy curve\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo14**</font> : Evaluation du modèle CNN sur les données de test. Afficher l'accuracy obtenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = CNN_model._____(_____, _____, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le CNN a une accuracy de {score[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les métriques (precision, recall...) et la matrice de confusion du CNN (sur les données de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predict function returns a 2-dimension array (10000, 10). \n",
    "# For each test input, it returns a probability for the 10 output classes\n",
    "y_softmax = CNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argmax numpy function returns the class having the highest probability\n",
    "y_pred = np.argmax(y_softmax, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo15**</font> : A l'aide la fonction `classification_report` afficher la précision, recall et f1-score pour le CNN. Conclure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(_____, _____, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">**Exo16**</font> : Afficher et analyser la matrice de confusion obtenue à partir du CNN. Quelles classes posent encore problème? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "labels_to_display=[]\n",
    "for i in range(NUM_CLASS):\n",
    "    labels_to_display.append(i)\n",
    "    \n",
    "label_names = []\n",
    "label_ticks = []\n",
    "for key in label_map:\n",
    "  label_names.append(label_map[key])\n",
    "  label_ticks.append(key)\n",
    "    \n",
    "# Construction de la matrice de confusion\n",
    "cm = confusion_matrix(_____, _____, normalize=None, labels=labels_to_display)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = _____)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cmap = plt.get_cmap('Blues')\n",
    "disp.plot(ax=ax, cmap=cmap, xticks_rotation=\"vertical\")\n",
    "plt.xticks(label_ticks[0:NUM_CLASS], label_names[0:NUM_CLASS], rotation='vertical')\n",
    "plt.yticks(label_ticks[0:NUM_CLASS], label_names[0:NUM_CLASS], rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction à partir d'images du jeu de test\n",
    "- Prenons 25 images du jeu de test et voyons combien ont été correctment classées par le modèle CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Predictions\n",
    "pred = CNN_model.predict(X_test)\n",
    "print(pred)\n",
    "\n",
    "# Converting the predictions into label index \n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "print(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Actual vs. Predicted results\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, 25):\n",
    "    axes[i].imshow(test_images[i])\n",
    "    axes[i].set_title(\"True: %s \\nPredict: %s\" % (class_names[np.argmax(Y_test[i])], class_names[pred_classes[i]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
