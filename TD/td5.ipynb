{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 - Import and Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "#from keras.utils.data_utils import get_file\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import get_file, to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor Flow version : \" + tf.__version__)\n",
    "print(\"Keras version : \" + keras.__version__)\n",
    "print(\"Numpy version : \" + np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Retrieve data\n",
    "#### Download, cache and extract Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On défini une variable (dataset_dir) pour définir le répertoire où se situe le dataset\n",
    "dataset_dir = Path('datasets')\n",
    "# Si le fichier 'testing_list.txt est présent, c'est que le dataset a déjà été téléchargé/extrait \n",
    "if not (dataset_dir/'testing_list.txt').exists(): \n",
    "    # On télécharge et on extrait le dataset compressé dans le répertoire 'datasets'\n",
    "    get_file(None, \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
    "                    extract=True,\n",
    "                    file_hash=\"6b74f3901214cb2c2934e98196829835\",\n",
    "                    cache_dir='.',\n",
    "                    cache_subdir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following command if needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv -f datasets/speech_commands_v0.02.tar.gz/* datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo1**</font> : Ecoute de quelques fichiers audio\n",
    "- Ecoutez quelques fichiers audios avec un lecteur multimédia\n",
    "- Combien y a t-il de classes au total dans ce dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw spoken digits data from Google Speech Commands\n",
    "Nous n'allons pas chercher à classifier l'ensemble du dataset (ce serait trop long) mais seulement les enregistrements audio des 10 chiffres (0 à 9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste des classes pour le test (ordonnée par label)\n",
    "CLASSES = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "# La liste 'testing_list' contient le chemin et le nom de tous les échantillons audio (ligne par ligne) pour le test\n",
    "with (dataset_dir/'testing_list.txt').open() as f:\n",
    "    # Lecture du fichier (fread)\n",
    "    # splitlines() : méthode qui divise une chaîne en une liste. La division se fait aux sauts de ligne.\n",
    "    testing_list = f.read().splitlines()   # ex: right/bb05582b_nohash_3.wav\n",
    "\n",
    "# On initialise les listes pour l'entrainement et le test (données et labels)\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# glob(f'**/*.wav') : permet de lister tous les fichiers audio (extension .wav) présents\n",
    "# dans l'arborescence du répertoire 'datasets'\n",
    "for recording in dataset_dir.glob(f'**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES:       # On ignore les classes qui ne sont pas des chiffres\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name)   # On assigne le numéro de la classe à l'enregistrement audio\n",
    "    \n",
    "    # Ouverture et lecture des fichiers audio\n",
    "    with wave.open(str(recording)) as f:           # Read wave file\n",
    "        # On copie les données audio au format 16-bit signed integer dans un tableau numpy \n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy()\n",
    "    \n",
    "    # Conversion des données audio en format 32-bit floating-point\n",
    "    data = data.astype(np.float32)\n",
    "    # Toutes les données audio doivent faire 1 seconde exactement, soit 16000 samples (1 seul canal)\n",
    "    # On redimensionne si besoin en complétant avec des valeurs à 0 (zero-padding)\n",
    "    data.resize((16000, 1))\n",
    "\n",
    "    # if (str(recording.relative_to(dataset_dir))) in testing_list \n",
    "    # => NE MARCHE PAS sur mon PC car le chemin est indiqué avec des '\\' (Ex: five\\20174140_nohash_0.wav) \n",
    "    # alors que testing_list utilise des '/'\n",
    "    # La solution consiste donc à remplacer tous les '\\' par des '/'\n",
    "    \n",
    "    # On ne met dans le jeu de test que les enregistrements audio listés dans 'testing_list' \n",
    "    if (str(recording.relative_to(dataset_dir))).replace(\"\\\\\", \"/\") in testing_list: \n",
    "        # Assign to test set if file in test list\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fin de la construction du jeu de données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo2**</font> : Jeu de données\n",
    "- Observer la forme des données d'entrainement (`x_train`) et de test (`x_test`)\n",
    "- En déduire le nombre de données pour l'entrainement et pour le test (et donc la taille totale du jeu de données).\n",
    "- Quel est le pourcentage de données pour le test? et pour l'entrainement ?\n",
    "- Vérifier le nombre de classes pour l'entrainement et le test?\n",
    "- Déterminer le nombre d'échantillons/observations d'entrainement pour chaque classe. Est-ce que ce jeu de données est équilibré (en terme de nombre d'échantillons par classe)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3 - Preparing the data\n",
    "#### Normalisation des données d'entrainement et de test\n",
    "+ En retranchant la moyenne et en divisant par l'écart type, on donne à une variable une **moyenne nulle** et un **écart-type de 1**, similaire à une Loi normale centrée réduite .\n",
    "+ On parle de **normalisation Z-score**\n",
    "+ Cette transformation assigne à la variable **une majorité de valeurs comprises entre [−1,1]**, le résultat étant **moins dépendant  des valeurs aberrantes** (contrairement à la normalisation min-max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le jeu d'entrainement est utilisé comme référence pour la moyenne et l'écart type\n",
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "# Normalisation des données d'entrainement et de test\n",
    "print('Before normalization : Min={}, Max={}, Moy={}, StdDev={}'.format(x_train.min(), x_train.max(), x_train.mean(), x_train.std()))\n",
    "x_train -= x_mean\n",
    "x_test  -= x_mean\n",
    "x_train /= x_std\n",
    "x_test  /= x_std\n",
    "print('After normalization : Min={}, Max={}, Moy={}, StdDev={}'.format(x_train.min(), x_train.max(), x_train.mean(), x_train.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On mélange aléatoirement les données de test et on prend les 250 premières\n",
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "# On enregistre ces données dans des tableaux numpy et dans un fichier .csv\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4 - Build a CNN model with Keras\n",
    "Ce modèle CNN est issue de cet [article](https://arxiv.org/pdf/1610.00087.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(ZeroPadding1D(40))\n",
    "model.add(Conv1D(filters=128, kernel_size=80, strides=4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(AvgPool1D(15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=len(CLASSES)))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's summarize the constructed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo3**</font>: Etude du modèle CNN\n",
    "- Combien de couches de convolution/pooling comporte ce modèle CNN ?\n",
    "- Combien de filtres de convolution sont appliqués aux données audio d'entrée?\n",
    "- Quelles sont les dimensions des filtres de convolution ?\n",
    "- Quelle est la taille et le type du filtre de pooling?\n",
    "- Combien de neurones y-a-t-il à l'entrée du réseau fully-connected (i.e. Dense) ? \n",
    "- Combien de couches de neurones sont utilisées dans la partie fully-connected ?\n",
    "- Combien de neurones par couche sont utilisées dans la partie fully-connected ?\n",
    "- Combien de paramètres entrainables comportent ce modèle? \n",
    "- Retrouver par le calcul ce nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5-Smaller\n",
    "Nous allons utiliser un modèle plus petit, càd avec beaucoup moins de paramètres entrainables que le modèle décrit plus haut...<br>\n",
    "Nous allons ainsi réduire le temps nécessaire à l'entrainement du modèle tout en gardant de bonnes performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(AvgPool1D(2))\n",
    "model.add(ZeroPadding1D(20))\n",
    "model.add(Conv1D(filters=12, kernel_size=40, strides=8, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=12, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=24, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(filters=48, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=len(CLASSES)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's initialize hyper parameters before training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "# nb_epochs\n",
    "nb_epochs = 16  # 50\n",
    "# taille des lots\n",
    "batch_size = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compile the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde les poids du modèle avant entrainement. On pourra ainsi les recharger plus loin pour recommencer un apprentissage de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=nb_epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f'Test loss     : {score[0]:4.4f}')\n",
    "print(f'Test accuracy : {score[1]*100:4.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo4**</font>: Etude de la performance du CNN\n",
    "- Quelle précision obtenez-vous sur les données de test avec ce CNN?\n",
    "- Afficher l'historique de la loss et de l'accuracy en fonction du nombre d'epochs\n",
    "- Conclure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display the history of the loss according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history of the loss\n",
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display the history of the accuracy according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history of the accuracy\n",
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo5**</font>: Matrice de confusion\n",
    "+ Afficher la matrice de confusion pour les 10 classes de digits prédites\n",
    "+ Quels sont les chiffres qui comportent le plus de faux positifs ? Avez-vous une explication ?\n",
    "+ En vous aidant du TD3, afficher les métriques de précision, recall et f1-score\n",
    "+ Quelle métrique permet de confirmer le nombre important de faux positifs pour les 2 chiffres indiqués plus haut ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la matrice de confusion\n",
    "# A COMPLETER..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des métriques : précision, recall et f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo6**</font>: \n",
    "+ Ré-entrainer le modèle CNN durant 50 epochs cette fois-ci. \n",
    "+ Est-ce que les performances (en terme d'accuracy notamment) sont meilleures ? Si oui, que peut-on en conclure ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avant de relancer l'entrainement sur 50 epochs, on restaure les poids aléatoires initiaux (avant entrainement)\n",
    "model.load_weights('model.weights.h5')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegardez le modèle entrainé\n",
    "N'oubliez pas de sauvegarder votre modèle à la fin de l'entrainement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo7**</font>: Si vous avez le temps...\n",
    "+ Ré-entrainer le modèle CNN pour classifier les 8 classes suivantes: backward, down, forward, go, left, right, stop, up\n",
    "+ Evaluer les performances du modèles pour ces 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
