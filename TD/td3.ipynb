{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **TD3 IA - Classify hand-written digits using a CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives :\n",
    " - Recognizing handwritten digits\n",
    " - Understanding the principle of a classifier based on a Convolutional Neural NEtwork (CNN)\n",
    " - Implementation using Keras/TensorFlow \n",
    "\n",
    "\n",
    "The [MNIST dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) (Modified National Institute of Standards and Technology) is a must for Deep Learning.  \n",
    "It consists in __60,000 small images__ of handwritten digits for __learning__ and __10,000__ for __testing__.\n",
    "\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Retrieve data\n",
    " - Preparing the data\n",
    " - Create a CNN model\n",
    " - Train the model\n",
    " - Evaluate the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1 - Import and Init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys,os\n",
    "sys.path.append('..')\n",
    "\n",
    "# Our Lib\n",
    "#import tools.pwk as pwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's print the tools version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor Flow version : \" + tf.__version__)\n",
    "print(\"Keras version : \" + keras.__version__)\n",
    "print(\"Numpy version : \" + np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if a GPU is available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"CuDNN version: \", build.build_info['cudnn_version'])\n",
    "print(\"Cuda version: \", build.build_info['cuda_version'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2 - Retrieve data**\n",
    "MNIST is one of the most famous historic dataset.  \n",
    "This dataset is available from [Keras datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset from Keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Display the dimensions of the dataset\n",
    "print(\"train_images : \", x_train.shape)\n",
    "print(\"train_labels : \", y_train.shape)\n",
    "print(\"test_images  : \", x_test.shape)\n",
    "print(\"test_labels  : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_count = np.unique(y_train, return_counts=True)\n",
    "for i in range(len(train_labels_count[0])):\n",
    "    print(f\"Label {i} : {train_labels_count[1][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo1**</font> : \n",
    "* Etudier le code python de la cellule précédente. Que représentent ces valeurs?\n",
    "* Que constatez-vous à la vue de ces valeurs?\n",
    "* Afficher le % pour chaque classe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us visualize some digits..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize numbers, we can get help from matplotlib.<br>\n",
    "When we run the code below, we will get the greyscale visualization of the RGB codes as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = x_train[1]\n",
    "plt.imshow(digit, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Step 3 - Preparing the data**\n",
    "\n",
    "#### Before training the model, data need to be preprocessed to\n",
    " - get the data in the form expected by the network (**reshape**)\n",
    " - get all input values between [0, 1] (**normalization**)\n",
    " \n",
    "#### Reshape and normalize the data\n",
    "  - To be able **to use the dataset in Keras API**, we **need 4-dims numpy arrays**. Therefore, we need to **reshape our 3-dims array into 4-dims array**.<br>\n",
    "  - In addition, we **must normalize our data** as it is always required in neural network models. Here we **divide the data by 255** (which is the maximum value in grey scale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API (1 means that there is 1 channel)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)  # 1 means that there is 1 channel\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print('After normalization  : Min={}, max={}'.format(x_train.min(),x_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4 - Build a CNN model with Keras**\n",
    "\n",
    "Let's build a first CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add( keras.layers.Input((28,28,1)) )\n",
    "\n",
    "model.add( keras.layers.Conv2D(8, (3,3),  activation='relu') )\n",
    "model.add( keras.layers.MaxPooling2D((2,2)))\n",
    "model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add( keras.layers.Conv2D(16, (3,3), activation='relu') )\n",
    "model.add( keras.layers.MaxPooling2D((2,2)))\n",
    "model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add( keras.layers.Flatten()) \n",
    "\n",
    "model.add( keras.layers.Dense(100, activation='relu'))\n",
    "model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add( keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's summarize the constructed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo2**</font> : Etude du modèle CNN\n",
    "* Combien de couches de convolution comporte ce modèle ?\n",
    "* Combien de filtres de convolution sont appliqués aux images d'entrée?\n",
    "* Quelles sont les dimensions des filtres de convolution ?\n",
    "* Quelle est la taille et le type du filtre de pooling?\n",
    "* Combien de couches de neurones sont utilisées dans la partie fully-connected ?\n",
    "* Combien de neurones par couche sont utilisées dans la partie fully-connected ?\n",
    "\n",
    "* Dessiner sur une feuille (ou avec un logiciel, c'est encore mieux) **l'architecture du CNN** que nous venons de modéliser\n",
    "  * Faire apparaître les différentes **couches**, les **fonctions réalisées** et les **dimensions**\n",
    "  * Insérer l'image (utilisez votre téléphone et rangez-le après ;o)) dans votre notebook\n",
    "\n",
    "* Combien de paramètres entrainables comportent ce modèle? \n",
    "* Retrouver par le calcul ce nombre.\n",
    "* Comparer le nombre de paramètres entrainables du CNN par rapport aux modèles MLP du td2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's initialize hyper parameters before training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs      =  16     # an epoch is one complete pass through the training data (all the training data are seen by the model)\n",
    "                      # here, the model will see 20 times the complete training set\n",
    "batch_size  = 512     # the batch size is the number of training samples processed before the model is updated, \n",
    "                      # in other words the number of training examples in one forward/backward pass. \n",
    "                      # The higher the batch size, the more memory space but the faster the training time.\n",
    "# The number of iterations per epoch is defined as the ratio between the size of training set and the batch size.\n",
    "# Here, it will be equal to 60000/512 = 118\n",
    "learning_rate = 0.01  # the learning rate controls how much to change the model in response to the estimated error \n",
    "                      # each time the model weights are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compile the model. \n",
    "When compiling the model, we need to indicate :\n",
    " - an **optimizer** : the purpose of an optimizer is to adjust model parameters (weights and biaises) to minimize an error function (i.e. the loss)\n",
    " - a **loss function** : it is a function that compares the target and predicted output values; it measures how well the neural network models the training data. When training, we aim to minimize this loss between the predicted and target outputs.\n",
    " - some **metrics** : metrics are used to monitor and measure the performance of a model (during training and testing)\n",
    "\n",
    "Remark : It is possible to experiment with the optimizer, loss function, metrics (and epochs). Note that the adam optimizer usually out-performs the other optimizers...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer='adam',                          # default learning rate = 0.001\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's train the model\n",
    " - Keras `fit` is the method used for the model training on the data set for the specified number of fixed epochs.\n",
    " - Here, 20% of the training set (validation set) is used to evaluate the model during the training\n",
    " - The number of iterations per epoch is therefore equal to : (60000*0.8)/batch_size = 94 iterations\n",
    " - At each iteration, the parameters (weights and biaises) are updated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(  x_train, y_train,\n",
    "                      batch_size       = batch_size,\n",
    "                      epochs           = epochs,\n",
    "                      verbose          = 1,\n",
    "                      validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6 - Evaluate the model**\n",
    "\n",
    "Let's evaluate the model after training on **10000 test images**.<br>\n",
    "This part of the dataset (the test) has **never been seen before by the model**.<br>\n",
    "It is therefore a way to evaluate the **capability of the model to generalize** on new data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is by default equal to 32 for the Keras evaluate function\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(f'Test loss     : {score[0]:4.4f}')\n",
    "print(f'Test accuracy : {score[1]*100:4.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display the history of the loss according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history of the loss\n",
    "plt.plot(history.history['loss'], label='Loss (training data)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (validation data)')\n",
    "plt.title('Loss for MNIST')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display the history of the accuracy according to the number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history (Accuracy):\n",
    "plt.plot(history.history['accuracy'], label='Acc (training data)')\n",
    "plt.plot(history.history['val_accuracy'], label='Acc (validation data)')\n",
    "plt.title('Accuracy for MNIST')\n",
    "plt.ylabel('Acc value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo3**</font> : Performance du CNN\n",
    "+ Quelle précision obtenez-vous pour les données de test avec le CNN?\n",
    "+ Sur les 10000 données de test, combien de chiffres ont été classifiés incorrectement par le CNN?  \n",
    "+ Comparez les résultats obtenus entre les MLP du td2 et ce CNN en termes \n",
    "  + de précision (en %), \n",
    "  + de nombre d'erreurs (ou nb de chiffres classifiés incorrectement) \n",
    "  + et de nombre de paramètres\n",
    "+ Conclure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Affichage de la matrice de confusion matrix et des metriques de performance (precision, recall and f1-score)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "# The predict function returns a 2-dimension array (10000, 10). \n",
    "# For each test input, it returns a probability for the 10 output classes\n",
    "y_softmax = model.predict(x_test)\n",
    "\n",
    "# The argmax numpy function returns the class having the highest probability\n",
    "y_pred    = np.argmax(y_softmax, axis=-1)\n",
    "\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display the confusion matrix using scikit-learn python library\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=\"red\">**Exo4**</font> : Etude des résultats\n",
    "* Etudier les résultats statistiques générés\n",
    "* Revoir la définition des mesures de performance vue en cours (`accuracy`, `precision`, `recall` et `f1-score`). \n",
    "* Dans quel cas faut-il plutot utiliser la précision, le recall ou le f1-score?\n",
    "* A partir des résultats de la matrice de confusion, expliquer avec quelle chiffre le 4 est-il le plus confondu en terme de faux positifs (et combien de fois)? Comment expliquez-vous cela?\n",
    "* Pour quel chiffre la precision est la meilleure ?\n",
    "* Pour quel chiffre le recall (ou sensibilité) est le meilleur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Vos réponses</u>:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo5**</font> : Sauvegarde du modèle entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder votre modèle CNN entrainé en tant que fichier HDF5\n",
    "\n",
    "**Keras** possède un **format de sauvegarde** utilisant le HDF5 dont l'extension est .h5 (https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre votre code dans cette cellule\n",
    "model.save('CNN_MNIST_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Maintenant on peut **re-générer le modèle** depuis le dernier fichier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recréé exactement le même model, incluant poids et optimizer.\n",
    "loaded_model = tf.keras.models.load_model('CNN_MNIST_model.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modèle rechargé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = loaded_model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f'Test results - Loss: {loss} - Accuracy: {acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prédiction de chiffres sur des données de test**\n",
    "\n",
    "La fonction `predict` permet de classifier une image passée en paramètre (ici un chiffre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Test prediction\")\n",
    "for x in range(0, 5) :\n",
    "    to_predict = np.reshape(x_test[x], (1,28,28,1))    # l'entrée du CNN est une tenseur 28*28*1\n",
    "    test_prediction = loaded_model.predict(to_predict)\n",
    "    print(x, \"Prediction :\", np.argmax(test_prediction))\n",
    "    Image_name = \"Prediction : \"+ str(np.argmax(test_prediction))    # le résultat est le digit qui a la plus grande probabilité\n",
    "    plt.imshow(x_test[x].reshape(28,28), cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=\"red\">**Exo6**</font> : Faire une prédiction \"homemade\" à partir d'un digit dessiné sur paint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dessinez un chiffre en utilisant Paint par exemple. Sauvegarder le fichier en 28*28 pixels en \"homemade.jpg\" puis déplacez ce fichier là où se trouve le notebook jupyter (td3.ipynb) sur Colab (cf. le TD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforme le .jpg en tableau de valeur (array)\n",
    "img = Image.open('../../TD/images/homemade_5.jpg').convert(\"L\")\n",
    "im2arr0 = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche l'image\n",
    "plt.imshow(im2arr0, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever le commentaire s'il est nécessaire d'inverser les niveaux de gris (blanc->noir et noir->blanc)\n",
    "#im2arr0 = 255 - im2arr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reshape l'image pour pouvoir faire la prédiction avec le modèle CNN\n",
    "im2arr = np.reshape(im2arr0, (1,28,28,1))\n",
    "\n",
    "# On lance la prédiction\n",
    "homemade_prediction = loaded_model.predict(im2arr, verbose=1)\n",
    "\n",
    "# Et on affiche le résultat de la prédiction\n",
    "print(\"Homemade digit prediction : \", np.argmax(homemade_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=\"red\">**Exo7**</font> : Changement des hyper-paramètres\n",
    "\n",
    "Les hyper-paramètres sont les paramètres qui ne sont pas entrainables (contrairement aux poids et aux biais du modèle).<br>\n",
    "C'est au data scientist de fixer la valeur des différents hyper-paramètres...<br>\n",
    "Dans cet exercice, vous allez tester les performances du modèle CNN avec d'autres valeurs d'hyper-paramètres.\n",
    "+ **Changer le learning rate** de 0.01 à 0.1 et relancer l'entrainement du modèle. Que constatez-vous ? Expliquer.\n",
    "+ Relancer l'entrainement du modèle avec **32 epoch (au lieu de 16)** puis afficher la loss et l'accuracy en fonction du nombre d'epoch. Conclure.\n",
    "+ Relancer l'entrainement du modèle avec un **batch size de 1024 (au lieu de 512)**. Qu'est-ce que cela change? Quels sont les risques d'augmenter le batch size? Comparer le temps d'entrainement pour ces 2 valeurs de batch size. Conclure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">**Exo8**</font> : CNN model 2\n",
    " - Construisez un 2ème modèle de réseau de neurones convolutionnel (CNN).<br>\n",
    " - Réponde aux questions de l'exo2 sur ce nouveau modèle CNN.\n",
    " - Entrainer et evaluer ce modèle. Comparer avec le premier modèle CNN. Conclure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce réseau est constitué des couches suivantes:\n",
    "- 1 couche de **Convolution** avec **32 filtres** (kernel 3*3, activation relu)\n",
    "- 1 couche de **max pooling 2*2**\n",
    "- 1 couche de **dropout** (0.2)\n",
    "\n",
    "- 1 couche de **Convolution** avec **64 filtres** (kernel 3*3, activation relu)\n",
    "- 1 couche de **max pooling 2*2**\n",
    "- 1 couche de **dropout** (0.2)\n",
    "\n",
    "- 1 couche de **Convolution** avec **64 filtres** (kernel 3*3)\n",
    "- 1 couche de **dropout** (0.2)\n",
    "- Après un flatten...\n",
    "- 1 couche **Dense** de **64 neurones** (activation relu)\n",
    "- 1 couche de **dropout** (0.5)\n",
    "\n",
    "- 1 couche **Dense** de sortie de **10 neurones** (activation softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du modèle CNN n°2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "\n",
    "model2.add( keras.layers.Conv2D(32, kernel_size=(3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "# A COMPLETER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation et Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modèle sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des métriques et de la matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des résultats (comparaison avec le 1er modèle CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
